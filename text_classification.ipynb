{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(phase):\n",
    "    data = []\n",
    "    with codecs.open(f\"data/{phase}.csv\", \"r\", \"shift-jis\", \"ignore\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", quotechar='\"')\n",
    "        reader = list(reader)[1:]\n",
    "        for line in reader:\n",
    "            data.append(line[1:])\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344\n",
      "587\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"train\")\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "for row in data:\n",
    "    removed_text = row[0].replace(\".\", \"\").replace(\",\", \"\")\n",
    "    splited_text = removed_text.split()\n",
    "    data_x.append(splited_text)\n",
    "    data_y.append(row[1])\n",
    "\n",
    "# data_x = list(map(lambda x: x.split(), data[:, 0]))\n",
    "# data_y = data[:, 1]\n",
    "\n",
    "train_end_index = int(len(data_x) * 0.8)\n",
    "\n",
    "train_x = data_x[:train_end_index]\n",
    "test_x  = data_x[train_end_index:]\n",
    "\n",
    "train_y = data_y[:train_end_index]\n",
    "test_y  = data_y[train_end_index:]\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Executes', 'and', 'writes', 'portions', 'of', 'testing', 'plans,', 'protocols,', 'and', 'documentation', 'for', 'assigned', 'portion', 'of', 'application;', 'identifies', 'and', 'debugs', 'issues', 'with', 'code', 'and', 'suggests', 'changes', 'or', 'improvements']\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, matutils\n",
    "# 名詞のリストになった記事群\n",
    "\n",
    "dic = corpora.Dictionary(train_x)\n",
    "# 「出現頻度が20未満の単語」と「30%以上の文書で出現する単語」を排除\n",
    "# dic.filter_extremes(no_below = 20, no_above = 0.3)\n",
    "\n",
    "def toBow(splited_text):\n",
    "    tmp = dic.doc2bow(splited_text)\n",
    "    dense = list(matutils.corpus2dense([tmp], num_terms=len(dic)).T[0])\n",
    "    return dense\n",
    "\n",
    "train_x_bow = list(map(toBow, train_x))\n",
    "test_x_bow = list(map(toBow, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# コストパラメータやRBFカーネルパラメータはgrid_searchによって最適なパラメータを選択\n",
    "model = svm.SVC(C = 10, gamma = 0.1, kernel = 'rbf')\n",
    "# train_docはベクトル化した文書のリストp\n",
    "# labelsは文書のカテゴリのリスト\n",
    "model.fit(train_x_bow, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "predicted = model.predict(test_x_bow)\n",
    "acc          = metrics.accuracy_score(test_y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6047700170357752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.48      0.53       126\n",
      "           2       0.56      0.21      0.31        70\n",
      "           3       0.62      0.88      0.73       282\n",
      "           4       0.52      0.29      0.38       109\n",
      "\n",
      "    accuracy                           0.60       587\n",
      "   macro avg       0.57      0.47      0.49       587\n",
      "weighted avg       0.59      0.60      0.57       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test_y, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
